{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPOpz/djTG4Kc7NqLhDQEn9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wezz-git/AI-samples/blob/main/Volatility_Forecasting_(GARCH_vs_LSTM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wx-LDruIDdTm"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8db5ce4d",
        "outputId": "2f631b2e-5bd0-459c-8b48-4dccb31f569b"
      },
      "source": [
        "!pip install arch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arch\n",
            "  Downloading arch-8.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from arch) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from arch) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.12/dist-packages (from arch) (1.16.3)\n",
            "Requirement already satisfied: statsmodels>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from arch) (0.14.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from arch) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->arch) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->arch) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->arch) (2025.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.0->arch) (1.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->arch) (1.17.0)\n",
            "Downloading arch-8.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (981 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.3/981.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: arch\n",
            "Successfully installed arch-8.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from arch import arch_model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "Mp3jhFtMFju6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = yf.download('AAPL', start='2010-01-01', end='2023-12-31')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ip6XEpG5Gmng",
        "outputId": "0e285a8c-9adb-4123-b410-c370ecc751a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3748985763.py:1: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download('AAPL', start='2010-01-01', end='2023-12-31')\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Will need this to check the columns for datasets\n",
        "print(data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhjhOadpIp24",
        "outputId": "be159c08-b4ce-4846-f36e-0b104893100e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultiIndex([( 'Close', 'AAPL'),\n",
            "            (  'High', 'AAPL'),\n",
            "            (   'Low', 'AAPL'),\n",
            "            (  'Open', 'AAPL'),\n",
            "            ('Volume', 'AAPL')],\n",
            "           names=['Price', 'Ticker'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = data[['Close']].copy()"
      ],
      "metadata": {
        "id": "C-ymBOx0G4PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Return'] = np.log(df['Close'] / df['Close'].shift(1))\n",
        "\n",
        "#Drop the first NaN (Not a Number) value\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "OBaiBr1qI9iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate Realized Volatility\n",
        "df['realized_volatility'] = df['Return'].rolling(window=21).std() * np.sqrt(252)"
      ],
      "metadata": {
        "id": "H70QM80pJxe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "5q4bsnZpOj5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale Teturn for GARCH\n",
        "garch_return = df['Return'] * 100\n",
        "\n",
        "#Defire and fit the model\n",
        "model_garch = arch_model(garch_return, vol='Garch', p=1, q=1)\n",
        "model_garch_fit = model_garch.fit(update_freq=5)\n",
        "\n",
        "#get the forecasted volatility\n",
        "df ['garch_forecast'] = model_garch_fit.conditional_volatility / 100 * np.sqrt(252)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8Dfm9FQOuX1",
        "outputId": "9a7ab1ac-8675-4fd0-b721-0bd87ba1f695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:      5,   Func. Count:     37,   Neg. LLF: 7019.754430100437\n",
            "Iteration:     10,   Func. Count:     63,   Neg. LLF: 6696.756355784778\n",
            "Optimization terminated successfully    (Exit mode 0)\n",
            "            Current function value: 6696.755383953927\n",
            "            Iterations: 14\n",
            "            Function evaluations: 82\n",
            "            Gradient evaluations: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create data for LTSM\n",
        "data_for_ltsm = df['realized_volatility'].values\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data_for_ltsm.reshape(-1,1))"
      ],
      "metadata": {
        "id": "05iD0VXKQ1IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create sequences\n",
        "lookback = 30\n",
        "X, y = [], []\n",
        "for i in range(lookback, len(data_scaled)):\n",
        "    X.append(data_scaled[i-lookback:i, 0])\n",
        "    y.append(data_scaled[i, 0])\n",
        "\n",
        "X, y = np.array(X), np.array(y)\n",
        "\n",
        "#Reshape for LTSM\n",
        "X = np.reshape(X, (X.shape[0], X.shape[1], 1))"
      ],
      "metadata": {
        "id": "XKIH6sPTReps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train & Test split\n",
        "\n",
        "split_index = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:split_index], X[split_index:]\n",
        "y_train, y_test = y[:split_index], y[split_index:]"
      ],
      "metadata": {
        "id": "c7djwka8Xl7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build and fit the model\n",
        "\n",
        "model_ltsm = Sequential()\n",
        "model_ltsm.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "model_ltsm.add(Dropout(0.2))\n",
        "model_ltsm.add(LSTM(units=50))\n",
        "model_ltsm.add(Dropout(0.2))\n",
        "model_ltsm.add(Dense(units=1))\n",
        "\n",
        "model_ltsm.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model_ltsm.fit(X_train, y_train, epochs=50, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1tQ5u4SYBCb",
        "outputId": "d8e83385-9fa7-48ce-f8f9-378c80c434a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0131\n",
            "Epoch 2/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0024\n",
            "Epoch 3/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0017\n",
            "Epoch 4/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0019\n",
            "Epoch 5/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0016\n",
            "Epoch 6/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0015\n",
            "Epoch 7/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0013\n",
            "Epoch 8/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0012\n",
            "Epoch 9/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0013\n",
            "Epoch 10/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011\n",
            "Epoch 11/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0013\n",
            "Epoch 12/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011\n",
            "Epoch 13/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.6334e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011\n",
            "Epoch 16/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.7702e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011\n",
            "Epoch 18/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.2843e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.6929e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.0068e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 8.2765e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 9.7891e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.8174e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.8013e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.7848e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.8462e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.7566e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.4769e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.2798e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.0800e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.1271e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.0258e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.2549e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.0354e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.9671e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.9215e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.7032e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.2662e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 6.8175e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 5.0464e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.9248e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.1116e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.5337e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.4298e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.4315e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.7081e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.6416e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.6725e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.9507e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.6790e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f4785c209b0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LTSM Predictions\n",
        "predictions_ltsm = model_ltsm.predict(X_test)\n",
        "predictions_ltsm = scaler.inverse_transform(predictions_ltsm)\n",
        "y_test = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "#Garch predictions for the same period\n",
        "garch_test_forecast = df['garch_forecast'].iloc[split_index + lookback:]\n",
        "\n",
        "#calculate Error (RMSE)\n",
        "rmse_ltsm = np.sqrt(mean_squared_error(y_test, predictions_ltsm))\n",
        "rmse_garch = np.sqrt(mean_squared_error(y_test, garch_test_forecast.values))\n",
        "\n",
        "print(f\"LTSM RMSE: {rmse_ltsm}\")\n",
        "print(f\"GARCH RMSE: {rmse_garch}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y7sS94_bQoS",
        "outputId": "913b6213-e82d-4089-ce87-8dec4e77c94e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "LTSM RMSE: 0.016099092630026925\n",
            "GARCH RMSE: 0.04448077842974344\n"
          ]
        }
      ]
    }
  ]
}