{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO1QxxUgQaeQKWtHqyyQuO5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wezz-git/AI-samples/blob/main/Financial_Fraud_Detection_with_Imbalanced_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Business Problem:**\n",
        "\n",
        "You're a data scientist at a bank. The fraud department is losing millions. They need a model that can, in real-time, identify if a credit card transaction is fraudulent (1) or legitimate (0).\n",
        "\n",
        "**The \"Real-World\" Challenge: **\n",
        "\n",
        "This is a \"needle in a haystack\" problem. Over 99% of transactions are legitimate. This is called imbalanced data. If you're not careful, you'll build a model that's 99% accurate but catches 0% of the fraud. This is the exact same problem as the \"Accuracy Trap\" we discussed on Day 1, but in a real-world scenario.\n",
        "\n",
        "**Your Goal: **\n",
        "\n",
        "Build a model that is actually good at finding the \"needle\" (the fraud)."
      ],
      "metadata": {
        "id": "FVlY1AJ7cqIW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WaK1PivMcZTG",
        "outputId": "1efb2505-3079-4a1e-9ad2-31b0ebbdf1da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
            "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
            "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
            "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
            "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
            "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
            "\n",
            "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
            "0  M1979787155             0.0             0.0        0               0  \n",
            "1  M2044282225             0.0             0.0        0               0  \n",
            "2   C553264065             0.0             0.0        1               0  \n",
            "3    C38997010         21182.0             0.0        1               0  \n",
            "4  M1230701703             0.0             0.0        0               0  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6362620 entries, 0 to 6362619\n",
            "Data columns (total 11 columns):\n",
            " #   Column          Dtype  \n",
            "---  ------          -----  \n",
            " 0   step            int64  \n",
            " 1   type            object \n",
            " 2   amount          float64\n",
            " 3   nameOrig        object \n",
            " 4   oldbalanceOrg   float64\n",
            " 5   newbalanceOrig  float64\n",
            " 6   nameDest        object \n",
            " 7   oldbalanceDest  float64\n",
            " 8   newbalanceDest  float64\n",
            " 9   isFraud         int64  \n",
            " 10  isFlaggedFraud  int64  \n",
            "dtypes: float64(5), int64(3), object(3)\n",
            "memory usage: 534.0+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# This path assumes the file is in your main Colab folder\n",
        "file_name = '/content/sample_data/PS_20174392719_1491204439457_log.csv'\n",
        "\n",
        "# Load the DataFrame\n",
        "df = pd.read_csv(file_name)\n",
        "\n",
        "# Print the first 5 rows\n",
        "print(df.head())\n",
        "\n",
        "# Print the technical summary\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 'Imbalance' Check"
      ],
      "metadata": {
        "id": "4VSnhJNIhmuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## First, let's see the RAW count (how many of each)\n",
        "print(\"--- Raw Fraud Counts ---\")\n",
        "\n",
        "print(df['isFraud'].value_counts())\n",
        "\n",
        "\n",
        "## Now, let's see the PERCENTAGE (using your normalize=True)\n",
        "print(\"\\n--- Percentage of Total ---\")\n",
        "\n",
        "print(df['isFraud'].value_counts(normalize=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_R04SKU1hsEb",
        "outputId": "c0a75673-0263-4a6b-ab54-66386178c977"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Raw Fraud Counts ---\n",
            "isFraud\n",
            "0    6354407\n",
            "1       8213\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Percentage of Total ---\n",
            "isFraud\n",
            "0    0.998709\n",
            "1    0.001291\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing)"
      ],
      "metadata": {
        "id": "We8P2tUmwaIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Drop the columns we don't need (they are just IDs or useless)\n",
        "\n",
        "df_clean = df.drop(columns=['nameOrig', 'nameDest', 'isFlaggedFraud'])\n",
        "\n",
        "# 2. Use 'get_dummies' to convert the 'type' column\n",
        "# add drop_first=True as a pro-step to avoid redundant columns\n",
        "df_processed = pd.get_dummies(df_clean, drop_first=True)\n",
        "\n",
        "print(\"--- Processed Data ---\")\n",
        "print(df_processed.head())\n",
        "print(\"\\n--- New Data Summary ---\")\n",
        "df_processed.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "J-WP3XhkwXfm",
        "outputId": "8205aad2-95cd-415e-f684-43ea24af0fbf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Processed Data ---\n",
            "   step    amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
            "0     1   9839.64       170136.0       160296.36             0.0   \n",
            "1     1   1864.28        21249.0        19384.72             0.0   \n",
            "2     1    181.00          181.0            0.00             0.0   \n",
            "3     1    181.00          181.0            0.00         21182.0   \n",
            "4     1  11668.14        41554.0        29885.86             0.0   \n",
            "\n",
            "   newbalanceDest  isFraud  type_CASH_OUT  type_DEBIT  type_PAYMENT  \\\n",
            "0             0.0        0          False       False          True   \n",
            "1             0.0        0          False       False          True   \n",
            "2             0.0        1          False       False         False   \n",
            "3             0.0        1           True       False         False   \n",
            "4             0.0        0          False       False          True   \n",
            "\n",
            "   type_TRANSFER  \n",
            "0          False  \n",
            "1          False  \n",
            "2           True  \n",
            "3          False  \n",
            "4          False  \n",
            "\n",
            "--- New Data Summary ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6362620 entries, 0 to 6362619\n",
            "Data columns (total 11 columns):\n",
            " #   Column          Dtype  \n",
            "---  ------          -----  \n",
            " 0   step            int64  \n",
            " 1   amount          float64\n",
            " 2   oldbalanceOrg   float64\n",
            " 3   newbalanceOrig  float64\n",
            " 4   oldbalanceDest  float64\n",
            " 5   newbalanceDest  float64\n",
            " 6   isFraud         int64  \n",
            " 7   type_CASH_OUT   bool   \n",
            " 8   type_DEBIT      bool   \n",
            " 9   type_PAYMENT    bool   \n",
            " 10  type_TRANSFER   bool   \n",
            "dtypes: bool(4), float64(5), int64(2)\n",
            "memory usage: 364.1 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split Data & Baseline Model"
      ],
      "metadata": {
        "id": "k0NsIoN0kt88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# --- 1. Load the Data ---\n",
        "file_name = '/content/sample_data/PS_20174392719_1491204439457_log.csv'\n",
        "print(\"Loading 6.3 million rows... This may take 20-30 seconds.\")\n",
        "df = pd.read_csv(file_name)\n",
        "\n",
        "# --- 2. Data Cleaning & Preprocessing ---\n",
        "# Drop the columns we don't need\n",
        "df_cleaned = df.drop(columns=['nameOrig', 'nameDest', 'isFlaggedFraud'])\n",
        "\n",
        "# Use 'get_dummies' to convert the 'type' column (This fixes your error!)\n",
        "print(\"Processing data...\")\n",
        "df_processed = pd.get_dummies(df_cleaned, drop_first=True)\n",
        "\n",
        "# --- 3. Create 'y' and 'X' ---\n",
        "y = df_processed['isFraud']\n",
        "X = df_processed.drop(columns=['isFraud'])\n",
        "\n",
        "# --- 4. Split the data ---\n",
        "print(\"Splitting the data...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# --- 5. Create and Train the Baseline Model ---\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "print(\"Training the baseline Logistic Regression model... (This may take a minute)\")\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Training complete!\")\n",
        "\n",
        "# --- 6. Make predictions and print the 'pro' report ---\n",
        "predictions = model.predict(X_test)\n",
        "print(\"\\n--- Baseline Model Classification Report ---\")\n",
        "print(classification_report(y_test, predictions, target_names=['Legit (0)', 'Fraud (1)']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8qvzieJy9zJ",
        "outputId": "9136642f-179a-487a-c19b-af8bb814e930",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 6.3 million rows... This may take 20-30 seconds.\n",
            "Processing data...\n",
            "Splitting the data...\n",
            "Training the baseline Logistic Regression model... (This may take a minute)\n",
            "Training complete!\n",
            "\n",
            "--- Baseline Model Classification Report ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Legit (0)       1.00      1.00      1.00   1906351\n",
            "   Fraud (1)       0.90      0.49      0.64      2435\n",
            "\n",
            "    accuracy                           1.00   1908786\n",
            "   macro avg       0.95      0.75      0.82   1908786\n",
            "weighted avg       1.00      1.00      1.00   1908786\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"Real\" Solution: SMOTE (Synthetic Minority Over-sampling Technique). It's a \"magic\" data-prep step)"
      ],
      "metadata": {
        "id": "QGkqWWX90Fil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# --- 1. Load the Data ---\n",
        "file_name = '/content/sample_data/PS_20174392719_1491204439457_log.csv'\n",
        "print(\"Loading 6.3 million rows...\")\n",
        "df = pd.read_csv(file_name)\n",
        "\n",
        "# --- 2. Take a 10% sample to make it run faster ---\n",
        "print(\"Taking a 10% sample to speed up the process...\")\n",
        "df_sample = df.sample(frac=0.1, random_state=42)\n",
        "\n",
        "# --- 3. Data Cleaning & Preprocessing (FIX 1: Use df_sample) ---\n",
        "print(\"Processing data...\")\n",
        "df_cleaned = df_sample.drop(columns=['nameOrig', 'nameDest', 'isFlaggedFraud'])\n",
        "df_processed = pd.get_dummies(df_cleaned, drop_first=True)\n",
        "\n",
        "# --- 4. Create 'y' and 'X' ---\n",
        "y = df_processed['isFraud']\n",
        "X = df_processed.drop(columns=['isFraud'])\n",
        "\n",
        "# --- 5. Split the data ---\n",
        "print(\"Splitting the data...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# --- 6. THE 'PRO' STEP: FIX THE IMBALANCE WITH SMOTE ---\n",
        "print(\"Applying SMOTE... (This will be much faster now)\")\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f\"Original training shape: {len(y_train)}\")\n",
        "print(f\"New balanced training shape: {len(y_train_balanced)}\")\n",
        "\n",
        "# --- 7. Train the ADVANCED Model (on the BALANCED data) ---\n",
        "model_rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "\n",
        "print(\"Training the RandomForest model on the balanced data...\")\n",
        "model_rf.fit(X_train_balanced, y_train_balanced)\n",
        "print(\"Training complete!\")\n",
        "\n",
        "# --- 8. Make predictions and print the 'pro' report (FIX 2: Use model_rf) ---\n",
        "predictions_rf = model_rf.predict(X_test)\n",
        "print(\"\\n--- ADVANCED Model Classification Report (with SMOTE) ---\")\n",
        "print(classification_report(y_test, predictions_rf, target_names=['Legit (0)', 'Fraud (1)']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qBze0JzIfL9m",
        "outputId": "57f4fc26-651f-4184-806e-7e30eadcae1a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 6.3 million rows...\n",
            "Taking a 10% sample to speed up the process...\n",
            "Processing data...\n",
            "Splitting the data...\n",
            "Applying SMOTE... (This will be much faster now)\n",
            "Original training shape: 445383\n",
            "New balanced training shape: 889608\n",
            "Training the RandomForest model on the balanced data...\n",
            "Training complete!\n",
            "\n",
            "--- ADVANCED Model Classification Report (with SMOTE) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Legit (0)       1.00      1.00      1.00    190641\n",
            "   Fraud (1)       0.56      0.91      0.69       238\n",
            "\n",
            "    accuracy                           1.00    190879\n",
            "   macro avg       0.78      0.95      0.85    190879\n",
            "weighted avg       1.00      1.00      1.00    190879\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model:\n",
        "\n",
        "**Baseline (Logistic Regression)\t**   \n",
        "\n",
        "Precision(Fraud) 0.90 (90%)\t    Recall (Fraud)0.49 (49%)\n",
        "\n",
        "**Advanced (Random Forest + SMOTE)\t   **  \n",
        "\n",
        "Precision(Fraud)0.56 (56%)\t    Recall (Fraud)0.91 (91%)"
      ],
      "metadata": {
        "id": "tRv1UTVggj5v"
      }
    }
  ]
}